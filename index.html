<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="PAPO">
  <meta name="keywords" content="PAPO, RL, GRPO, Multimodal Reasoning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PAPO: Perception-Aware Policy Optimization for Multimodal Reasoning</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


  <script>
    document.addEventListener('DOMContentLoaded', function () {
      var toggles = document.querySelectorAll('.toggle-section');
      toggles.forEach(function(toggle) {
        toggle.addEventListener('click', function() {
          var content = document.getElementById(toggle.getAttribute('aria-controls'));
          content.classList.toggle('is-active');
          toggle.children[1].classList.toggle('fa-angle-down');
          toggle.children[1].classList.toggle('fa-angle-up');
        });
      });
    });
  </script>

  <style>
    .collapse-content {
      display: none;
      margin-top: 10px;
    }
    .collapse-content.is-active {
      display: block;
    }
    .toggle-section .icon.is-small {
      transition: transform 0.3s ease;
    }
    .toggle-section .fa-angle-up {
      transform: rotate(180deg);
    }
  </style>

  <style>
    .banner {
      background-color: #f5f5f5;
      padding: 10px 0;
      border-bottom: 1px solid #ddd;
    }
    .banner .container {
      display: flex;
      justify-content: center; /* Center the links horizontally */
      align-items: center;
      gap: 100px; /* Controls the spacing between links */
    }

    .banner a {
      color: #3273dc;
      text-decoration: none;
      font-weight: bold;
      margin: 0; /* Remove any additional margin */
      padding: 5px; /* Optional: Adjust padding around the links */
      font-size: 18px;
    }

    .banner a:hover {
      text-decoration: underline;
    }
  </style>

</head>
<body>


<!-- <section class="banner">
  <div class="container">
    <a href="https://github.com/X-PLUG/MobileAgent">Mobile-Agent Series</a>
    <a href="https://github.com/X-PLUG/MobileAgent/tree/main/Mobile-Agent">Mobile-Agent-v1</a>
    <a href="https://github.com/X-PLUG/MobileAgent/tree/main/Mobile-Agent-v2">Mobile-Agent-v2</a>
    <a href="https://github.com/X-PLUG/MobileAgent/tree/main/Mobile-Agent-E">Mobile-Agent-E</a>
  </div>
</section> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <!-- <img src="./static/images/icon.png" alt="Icon" style="vertical-align: middle; height: 70px; margin-right: 10px; margin-bottom: 9px"> -->
            PAPO: Perception-Aware Policy Optimization for Multimodal Reasoning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://mikewangwzhl.github.io/">Zhenhailong Wang</a><sup>1*‚Ä†</sup>,
            </span>
            <span class="author-block">
              <a href="">Xuehang Guo</a><sup>1*</sup>,
            </span>
            <span class="author-block">
              <a href="">Sofia Stoica</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=qZYvce8AAAAJ&hl=en">Haiyang Xu</a><sup>2‚Ä†</sup>,
            </span>
            <span class="author-block">
              <a href="">Hongru Wang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://hyeonjeongha.github.io/">Hyeonjeong Ha</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://xiusic.github.io/">Xiusi Chen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://yangyi-chen.github.io/">Yangyi Chen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=uIUfGxYAAAAJ&hl=zh-CN">Ming Yan</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=9r98PpoAAAAJ&hl=zh-CN">Fei Huang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://blender.cs.illinois.edu/hengji.html">Heng Ji</a><sup>1‚Ä†</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Illinois Urbana-Champaign,</span>
            <span class="author-block"><sup>2</sup>Alibaba Group</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution,</span>
            <span class="author-block"><sup>‚Ä†</sup>Corresponding Author</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- arxiv Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>PDF</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/MikeWangWZHL/VDLM/raw/main/Mobile-Agent-E/static/videos/vdlm_teaser_vid.mp4"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>
              <!-- Model Link. -->
              <!-- <span class="link-block">
                <a href="https://huggingface.co/mikewang/PVD-160k-Mistral-7b"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">ü§ó</p>
                  </span>
                  <span>Model</span>
                </a> -->
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href=""
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <p style="font-size:18px">ü§ó</p>
                </span>
                <span>Model (coming soon)</span>
                </a>
              </span>
              <!-- Demo link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/MikeWangWZHL/VDLM/blob/main/demo.ipynb"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <p style="font-size:18px">üöÄ</p>
                  </span>
                  <span>Demo</span>
                </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Abstract -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be a highly effective strategy for endowing Large Language Models (LLMs) with robust multi-step reasoning abilities. However, its design and optimizations remain tailored to purely textual domains, resulting in suboptimal performance when applied to multimodal reasoning tasks. In particular, we observe that a major source of error in current multimodal reasoning lies in the perception of visual inputs.
            To address this bottleneck, we propose Perception-Aware Policy Optimization (PAPO), a simple yet effective extension of GRPO that encourages the model to learn to perceive while learning to reason. Notably, PAPO does not rely on additional data curation, external reward models, or proprietary models.
            Specifically, we introduce the Implicit Perception Loss in the form of a KL divergence term to the GRPO objective, which, despite its simplicity, yields significant overall improvements (4.4%) on diverse multimodal benchmarks. The improvements are more pronounced, up to 8.0%, on heavily vision-dependent tasks. We also observe a substantial reduction (30.5%) in perception errors, indicating improved perceptual capabilities with PAPO. We conduct comprehensive analysis of PAPO and identify a unique loss hacking issue, which we rigorously analyze and mitigate through a Double Entropy Loss.
            Overall, our work introduces a deeper integration of perception-aware supervision into RLVR learning objectives and lays the groundwork for a new RL framework that encourages visually grounded reasoning.
          </p>
        </div>
        <!-- <figure>
          <img src="" alt="teaser." class="teaser"/>
          <figcaption class="has-text-centered">
            <b>Figure 1:</b> 
        </figure> -->
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Perception Bottleneck in Multimodal Reasoning</h2>
        <br>
        <div style="text-align: center;">
          <figure id="teaser">
              <img src="./static/images/teaser.png" alt="teaser" class="teaser" style="width: 800px;"/>
              <figcaption class="has-text-centered"><b>Figure 1:</b> Comprehensive error-type breakdown and inference example between GRPO and PAPO.</figcaption>
          </figure>
        </div>
        <br>
        <p>
            We first investigate the question: <em>Are there unique challenges in multimodal reasoning that do not arise in text-only settings?</em> We follow a typical <a href="https://github.com/hiyouga/EasyR1">GRPO</a> pipeline to train <a href="https://huggingface.co/collections/Qwen/qwen25-vl-6795ffac22b334a837c0f9a5">Qwen2.5-VL-3B</a> on <a href="https://huggingface.co/datasets/TIGER-Lab/ViRL39K">ViRL39K</a> and manually examine and categorize error types based on 200 error instances sampled from four benchmarks. To our surprise, we find that the majority of errors, 67.0%, stem from poor perception. We hypothesize that this bottleneck in perception is due to the GRPO objective not providing any incentive for the model to generate visually grounded responses.
        </p>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">PAPO Algorithm</h2>
        <br>
        <div style="text-align: center;">
          <figure id="teaser">
              <img src="./static/images/method.png" alt="teaser" class="teaser" style="width: 940px;"/>
              <figcaption class="has-text-centered"><b>Figure 2:</b> Overview of PAPO objective.</figcaption>
          </figure>
        </div>
        <br>
        <p>
          We propose <b>Perception-Aware Policy Optimization (PAPO)</b>, a novel RLVR algorithm that enhances multimodal reasoning through visually grounded optimization. PAPO is a simple extension of GRPO that directly incorporates a perception-aware <b>internal supervision signal</b> into its training objective. Notably,  <b>PAPO does not rely on additional data curation, external reward models, or proprietary models.</b>
        </p>
        <br>
        <div style="text-align: center;">
          <figure id="teaser">
            <img src="./static/images/method_objective.png" alt="teaser" class="teaser" style="width: 940px;"/>
            <figcaption class="has-text-centered"><b>Figure 3:</b> Comparison of GRPO and PAPO objectives.</figcaption>
          </figure>
        </div>
        <br>
        <p>
          TODO: Add more details about the objectives here...
        </p>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>
        <h3 class="title is-5">Main Results</h3>

        <div style="text-align: center;">
          <figure id="teaser">
              <img src="./static/images/main_results.png" alt="teaser" class="teaser" style="width: 1000px;"/>
              <figcaption class="has-text-centered"><b>Table 1:</b> TODO: copy the caption.</figcaption>
          </figure>
        </div>
        <p>
          TODO: Add some analysis here, such as more pronounced on vision-dependent tasks.
        </p>
        <br>
        <h3 class="title is-5">PAPO + Remove Reference KL</h3>
        <p>
          TODO: Add table; Add results here...
        </p>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Ablation Study</h2>
        <h3 class="title is-5">Impact of Implicit Perception Loss Weighting</h3>
        <p>
          TODO: Add table; Add results here...
        </p>
        <br>
        <h3 class="title is-5">Impact of Masking Strategy</h3>
        <p>
          TODO: Add table; Add table; Add results here...
        </p>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Implicit Perception Loss Hacking</h2>
        <p>
          TODO: explain what is the hacking
        </p>
        
        <br>
        <h3 class="title is-5">Collapsing Behavior</h3>
        <p>
          TODO:
        </p>

        <br>
        <h3 class="title is-5">Early Signs</h3>
        <p>
          TODO:
        </p>
        
        <br>
        <h3 class="title is-5">Influential Factors</h3>
        <p>
          TODO:
        </p>
        
        <br>
        <h3 class="title is-5">How To Prevent?</h3>
        <p>
          TODO:
        </p>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Resources</h2>

        <p>
          üçâ <a href=""> <b>PAPO Code (coming soon)</b> </a>
        </p>        
        <p>
          ü§ó <a href=""><b>Models (coming soon)</b></a>
        </p>
        
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
    
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
      href="">
      <i class="fas fa-file-pdf"></i>
    </a>
    <a class="icon-link" href="https://github.com/mikewangwzhl" class="external-link" disabled>
      <i class="fab fa-github"></i>
    </a>
  </div> -->
  <div class="content has-text-centered">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <!-- <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p> -->
          <p>
            This website's template is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>. We thank the authors for open-sourcing their code.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
